# This snakefile runs deconvolution for each of the various packages we've implemented. 

# ---------
# Variables
# ---------

# Bulk types: all sets of samples to deconvolve, including true bulk and pseudobulk.
# True bulk types: We ran bulk RNA-seq on the samples in three separate ways: rRNA depletion on
# tumor chunks, dissociation and then rRNA depletion, and dissociation and then polyA (3') capture.
# Pseudobulk types: Different simulated pseudobulk datasets, derived from our single-cell data.
# Methods: the deconvolution packages we have implemented. Citation in the corresponding R script.
# Samples: the eight samples used in the pilot. This info is needed to run salmon.
# Threads: number of cores to run on.

BULK_TYPES = ['chunk_ribo', 'dissociated_ribo', 'dissociated_polyA', 'realistic', 'even', 'weighted', 'sparse']
TRUEBULKTYPES = ['chunk_ribo', 'dissociated_ribo', 'dissociated_polyA']
PSEUDOBULKTYPES = ['realistic', 'even', 'weighted', 'sparse']
#METHODS = [ 'music', 'bisque', 'bayesprism', 'epic', 'quantiseq', 'mcpcounter', 'xcell', 'consensus_tme', 'abis', 'timer', 'cibersortx', 'immucellai'] # etc.
METHODS = [ 'cibersortx' ]
SAMPLES = ['2251', '2267', '2283', '2293', '2380', '2428', '2467', '2497']
THREADS = 6

dir_results = "/home/ariel/Documents/scRNA/deconvolution_pilot/data/deconvolution_output/"
dir_inputs = "/home/ariel/Documents/scRNA/deconvolution_pilot/data/deconvolution_input/"
dir_bulk = "/home/ariel/Documents/scRNA/sc-cancer-hgsc/data/bulk_tumors"
dir_single = "/home/ariel/Documents/scRNA/sc-cancer-hgsc/data/tumors"
dir_index = "/home/ariel/Documents/scRNA/sc-cancer-hgsc/data/index"

wildcard_constraints:
	truebulktype="[A-Za-z]+_[A-Za-z]+",
	pseudobulktype="[A-Za-z]+"

# --------
# Workflow
# --------

rule all:
	input:
		expand(dir_results + "{bulk_type}/{method}_results.tsv", bulk_type=BULK_TYPES, method=METHODS, truebulktype=TRUEBULKTYPES)

rule run_music:
	input:
		dir_inputs + "labeled_single_cell_profile.rds",
		dir_inputs + "bulk_data_{bulk_type}.tsv"
	output:
		dir_results + "{bulk_type}/music_results.tsv"
	threads:
		THREADS
	script:
		"run_music.R"

rule run_bisque:
	input:
		dir_inputs + "labeled_single_cell_profile.rds",
		dir_inputs + "bulk_data_{bulk_type}.tsv"
	output:
		dir_results + "{bulk_type}/bisque_results.tsv"
	threads:
		THREADS
	script:
		"run_bisque.R"

rule run_bayesprism:
	input:
		dir_inputs + "labeled_cell_state_profile.rds",
		dir_inputs + "bulk_data_{bulk_type}.tsv"
	output:
		dir_results + "{bulk_type}/bayesprism_results.tsv"
	threads: 
		THREADS
	script:
		"run_bayesprism.R"

rule run_epic:
	input:
		dir_inputs + "normalized_data_{bulk_type}.tsv"
	output:
		dir_results + "{bulk_type}/epic_results.tsv"
	script:
		"run_epic.R"

rule run_mcpcounter:
	input:
		dir_inputs + "normalized_data_{bulk_type}.tsv"
	output:
		dir_results + "{bulk_type}/mcpcounter_results.tsv"
	script:
		"run_mcpcounter.R"

rule run_quantiseq:
	input:
		dir_inputs + "normalized_data_{bulk_type}.tsv"
	output:
		dir_results + "{bulk_type}/quantiseq_results.tsv"
	script:
		"run_quantiseq.R"

rule run_xcell:
	input:
		dir_inputs + "normalized_data_{bulk_type}.tsv"
	output:
		dir_results + "{bulk_type}/xcell_results.tsv"
	script:
		"run_xcell.R"

rule run_consensus_tme:
	input:
		dir_inputs + "normalized_data_{bulk_type}.tsv"
	output:
		dir_results + "{bulk_type}/consensus_tme_results.tsv"
	script:
		"run_consensus_tme.R"

rule run_abis:
	input:
		dir_inputs + "normalized_data_{bulk_type}.tsv"
	output:
		dir_results + "{bulk_type}/abis_results.tsv"
	script:
		"run_abis.R"

rule run_timer:
	input:
		dir_inputs + "normalized_data_{bulk_type}.tsv"
	output:
		dir_results + "{bulk_type}/timer_results.tsv"
	script:
		"run_timer.R"


# Read in credentials for cibersortx license
def get_token(wildcards):
	with open("cibersort_token.txt", "r") as f:
		token = f.read().strip()
	return token

def get_username(wildcards):
	with open("cibersort_username.txt", "r") as f:
		username = f.read().strip()
	return username

rule run_cibersortx:
	input:
		scdata = dir_inputs + "cibersortx_single_cell_profile.tsv",
		bulkdata = dir_inputs + "bulk_data_{bulk_type}.tsv"
	output:
		dir_results + "{bulk_type}/CIBERSORTx_Results.txt"
	threads:
		THREADS
	params:
		input_dir = dir_inputs,
		output_dir = dir_results + "{bulk_type}",
		token=get_token,
		username=get_username
	shell:
		"""docker run -v {params.input_dir}:/src/data -v {params.output_dir}:/src/outdir cibersortx/fractions --username {params.username} --token {params.token} --single_cell TRUE --refsample {input.scdata} --mixture {input.bulkdata} --verbose TRUE"""

rule run_immucellai:
	input:
		dir_inputs + "normalized_data_{bulk_type}.tsv"
	output:
		dir_results + "{bulk_type}/immucellai_results.tsv"
	script:
		"run_immucellai.R"

# --------------
# Helper scripts 
# --------------

# These scripts produce input files needed to run one or more deconvolution methods.

# Formats the single cell matrix as needed for cibersortx
rule get_labels_as_colnames:
	input:
		dir_inputs + "labeled_single_cell_profile.rds"
	output:
		dir_inputs + "cibersortx_single_cell_profile.tsv"
	script:
		"get_cibersort_matrix.R"

# The output file is write protected so it's not letting me rename,
# so I'll copy it to the name in the format I want.
rule mutate_cibersortx:
	input:
		dir_results + "{bulk_type}/CIBERSORTx_Results.txt"
	output:
		dir_results + "{bulk_type}/cibersortx_results.tsv"
	script:
		"get_formatted_cibersort_results.R"

# Write STAR output into a unified matrix
rule make_bulk_data_matrix:
	output:
		dir_inputs + "bulk_data_{truebulktype}.tsv"
	priority:
		10000
	script:
		"get_bulk_matrix.R"

# Write salmon output into a unified matrix
rule make_tpm_bulk_data_matrix:
	input:
		salmon = lambda wildcards: \
		  [dir_bulk + "/{0}/{1}/salmon/quant.sf".format(sampleid, wildcards.truebulktype) \
		  for sampleid in SAMPLES
		  ],
	output:
		dir_inputs + "normalized_data_{truebulktype}.tsv"
	priority:
		9000
	script:
		"get_normalized_bulk_matrix.R"

# Make pseudobulk files
rule get_pseudobulk_files:
	output:
		dir_inputs + "bulk_data_{pseudobulktype}.tsv",
		dir_inputs + "normalized_data_{pseudobulktype}.tsv"
	script:
		"get_simulated_pseudobulk.R"

# Generates a reference profile object for methods using single cell.
rule get_single_cell_labels:
	output:
		dir_inputs + "labeled_single_cell_profile.rds"
	script:
		"get_single_cell_labels.R"

# BayesPrism requires two levels of information, cell type and cell state. This
# script refactors the existing cellTypist data to fit the needed parameters.
rule get_cell_states:
	input:
		dir_inputs + "labeled_single_cell_profile.rds"
	output:
		dir_inputs + "labeled_cell_state_profile.rds"
	script:
		"get_cell_states.R"

# Some deconvolution methods require TPM values instead of raw count values. The
# preferred way to get TPM values is by quantifying the transcriptome via salmon.
rule run_salmon:
	input:
		r1 = dir_bulk + "/{sample}/{truebulktype}/{sample}_R1_merged.fastq.gz",
		r2 = dir_bulk + "/{sample}/{truebulktype}/{sample}_R2_merged.fastq.gz",
		bin = dir_index + "/salmon_index/refseq.bin"
	output:
		dir_bulk + "/{sample}/{truebulktype}/salmon/quant.sf"
	params:
		index = dir_index + "/salmon_index",
		outdir = dir_bulk + "/{sample}/{truebulktype}/salmon"
	shell:
		"salmon quant -i {params.index} -l A -1 {input.r1} -2 {input.r2} -o {params.outdir} -p {THREADS}"

# Salmon requires a previously generated index.
rule get_salmon_index:
	output:
		dir_index + "salmon_index/refseq.bin"
	params:
		index = dir_index + "/salmon_index",
		genome = dir_index + "/gencode.v32.transcripts.fa.gz",
                genes = dir_index + "/refdata-gex-GRCh38-2020-A/genes/genes.gtf"
	shell:
		"salmon index -i {params.index} -t {params.genome} -k 23 -p {THREADS} --gencode"
